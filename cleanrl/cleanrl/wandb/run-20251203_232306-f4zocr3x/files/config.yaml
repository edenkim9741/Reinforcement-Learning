_wandb:
    value:
        cli_version: 0.23.0
        code_path: code/cleanrl/cleanrl/ppo_chess_vs_stockfish.py
        e:
            ts6i62nwm1e3g4rv4hhap7cmr7qqaihe:
                args:
                    - --mode
                    - curriculum
                    - --total-timesteps
                    - "16000000"
                    - --num-envs
                    - "16"
                    - --eval-episodes
                    - "50"
                    - --data-path
                    - ../data/stockfish_pretrain_data_v4.npz
                    - --use-wandb
                codePath: cleanrl/cleanrl/ppo_chess_vs_stockfish.py
                codePathLocal: ppo_chess_vs_stockfish.py
                cpu_count: 12
                cpu_count_logical: 20
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "1966736678912"
                        used: "684290494464"
                email: edenkim9741@gmail.com
                executable: /home/eden/Documents/JNU/2025-2/Reinforcement-Learning/cleanrl/.venv/bin/python
                git:
                    commit: c32859e6da691076047e479a3c7905ad748915d7
                    remote: git@github.com:edenkim9741/Reinforcement-Learning.git
                gpu: NVIDIA GeForce RTX 3070
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 5888
                      memoryTotal: "8589934592"
                      name: NVIDIA GeForce RTX 3070
                      uuid: GPU-0b6c1f78-fd88-aa7f-110b-d2bc34b25898
                host: eden-CVL
                memory:
                    total: "33493585920"
                os: Linux-6.11.0-29-generic-x86_64-with-glibc2.39
                program: /home/eden/Documents/JNU/2025-2/Reinforcement-Learning/cleanrl/cleanrl/ppo_chess_vs_stockfish.py
                python: CPython 3.10.19
                root: /home/eden/Documents/JNU/2025-2/Reinforcement-Learning/cleanrl/cleanrl
                startedAt: "2025-12-03T14:23:06.770514Z"
                writerId: ts6i62nwm1e3g4rv4hhap7cmr7qqaihe
        m: []
        python_version: 3.10.19
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
            "4": 3.10.19
            "5": 0.23.0
            "8":
                - 2
            "12": 0.23.0
            "13": linux-x86_64
anneal_lr:
    value: true
channels:
    value: 128
clip_coef:
    value: 0.2
clip_vloss:
    value: true
ent_coef:
    value: 0.01
eval_episodes:
    value: 50
eval_interval:
    value: 10
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
learning_rate:
    value: 0.0003
log_dir:
    value: runs
max_grad_norm:
    value: 0.5
mode:
    value: curriculum
model_dir:
    value: models
norm_adv:
    value: true
num_envs:
    value: 16
num_minibatches:
    value: 8
num_res_blocks:
    value: 4
num_steps:
    value: 256
phase1_epochs:
    value: 20
phase2_ratio:
    value: 0.6
phase3_ratio:
    value: 0.4
pretrain_episodes:
    value: 500
pretrain_lr:
    value: 0.001
seed:
    value: 42
self_play_ratio:
    value: 0.5
stockfish_path:
    value: /usr/games/stockfish
stockfish_skill:
    value: 0
stockfish_time_limit:
    value: 0.01
target_kl:
    value: null
total_timesteps:
    value: 16000000
update_epochs:
    value: 4
use_wandb:
    value: true
vf_coef:
    value: 0.5
